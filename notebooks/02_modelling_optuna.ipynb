{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de4fe12",
   "metadata": {},
   "source": [
    "here we test out dataset on different poweful ml models such as RandomForest, SVM, Boostings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96fd3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fef9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = Path(os.getcwd()).parent / \"data\" / \"raw\" / \"train_titanic.csv\"\n",
    "PROCESSED_DATA_PATH = Path(os.getcwd()).parent / \"data\" / \"processed\" / \"titanic_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c4869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeGroup_median</th>\n",
       "      <th>Fare_log</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>FamilySize_cluster</th>\n",
       "      <th>Title_transformed</th>\n",
       "      <th>Has_Cabin_Number</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>3</td>\n",
       "      <td>MidSizeFamily</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>MidSizeFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>3</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>1</td>\n",
       "      <td>MidSizeFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>3</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex AgeGroup_median  Fare_log  Pclass FamilySize_cluster  \\\n",
       "0    male           Adult  2.110213       3      MidSizeFamily   \n",
       "1  female           Adult  4.280593       1      MidSizeFamily   \n",
       "2  female           Adult  2.188856       3              Alone   \n",
       "3  female           Adult  3.990834       1      MidSizeFamily   \n",
       "4    male           Adult  2.202765       3              Alone   \n",
       "\n",
       "  Title_transformed  Has_Cabin_Number  Survived  \n",
       "0                Mr                 0         0  \n",
       "1               Mrs                 1         1  \n",
       "2              Miss                 0         1  \n",
       "3               Mrs                 1         1  \n",
       "4                Mr                 0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(PROCESSED_DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6bd44",
   "metadata": {},
   "source": [
    "to choose which model to use, it is mostly decided by roc-auc metric. Roc-Auc gives the extent the model can distinguish target classes. we try to look for the best roc-auc with the default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac36fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def make_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "    num_cols = X.select_dtypes(include=[\"int64\", \"float64\", \"int32\", \"float32\"]).columns.tolist()\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=True))\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, num_cols),\n",
    "            (\"cat\", cat_pipe, cat_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def make_pipeline(model, X: pd.DataFrame) -> Pipeline:\n",
    "    preprocessor = make_preprocessor(X)\n",
    "    return Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "\n",
    "def evaluate_models_cv(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    models: dict,\n",
    "    n_splits: int = 5,\n",
    "    seed: int = 42,\n",
    "    return_oof: bool = True\n",
    ") -> dict:\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        pipe = make_pipeline(model, X)\n",
    "\n",
    "        # cross_validate gives per-fold scores + timing\n",
    "        cv_out = cross_validate(\n",
    "            pipe, X, y,\n",
    "            cv=cv,\n",
    "            scoring=\"roc_auc\",\n",
    "            return_train_score=False,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        fold_scores = cv_out[\"test_score\"]\n",
    "        mean_auc = float(np.mean(fold_scores))\n",
    "        std_auc = float(np.std(fold_scores))\n",
    "\n",
    "        oof_auc = None\n",
    "        if return_oof:\n",
    "            # For AUC we need scores (probabilities or decision function)\n",
    "            # cross_val_predict supports method='predict_proba' or 'decision_function'.\n",
    "            # We try predict_proba first; if not available, fall back to decision_function.\n",
    "            try:\n",
    "                oof_scores = cross_val_predict(\n",
    "                    pipe, X, y, cv=cv, method=\"predict_proba\", n_jobs=-1\n",
    "                )[:, 1]\n",
    "            except Exception:\n",
    "                oof_scores = cross_val_predict(\n",
    "                    pipe, X, y, cv=cv, method=\"decision_function\", n_jobs=-1\n",
    "                )\n",
    "            oof_auc = float(roc_auc_score(y, oof_scores))\n",
    "\n",
    "        results[name] = {\n",
    "            \"roc_auc_mean\": mean_auc,\n",
    "            \"roc_auc_std\": std_auc,\n",
    "            \"fold_scores\": fold_scores,\n",
    "            \"oof_roc_auc\": oof_auc,\n",
    "            \"fit_time_mean\": float(np.mean(cv_out[\"fit_time\"])),\n",
    "            \"score_time_mean\": float(np.mean(cv_out[\"score_time\"]))\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_cv_results(results: dict):\n",
    "    rows = []\n",
    "    for name, r in results.items():\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"roc_auc_mean\": r[\"roc_auc_mean\"],\n",
    "            \"roc_auc_std\": r[\"roc_auc_std\"],\n",
    "            \"oof_roc_auc\": r[\"oof_roc_auc\"],\n",
    "            \"fit_time_mean\": r[\"fit_time_mean\"]\n",
    "        })\n",
    "    summary = pd.DataFrame(rows).sort_values(\"roc_auc_mean\", ascending=False)\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "    print(\"\\nPer-fold scores:\")\n",
    "    for name, r in results.items():\n",
    "        print(f\"\\n{name}: {np.round(r['fold_scores'], 4)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a96223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model  roc_auc_mean  roc_auc_std  oof_roc_auc  fit_time_mean\n",
      "  LGBMClassifier      0.880566     0.014194     0.879164       4.555291\n",
      "GradientBoosting      0.878124     0.009720     0.877297       0.210541\n",
      "   XGBClassifier      0.877670     0.018398     0.875614       0.336835\n",
      "         SVC_RBF      0.868453     0.014430     0.870791       0.035320\n",
      "    RandomForest      0.861516     0.018192     0.861308       0.146548\n",
      "      GaussianNB      0.858991     0.017547     0.857226       0.026294\n",
      "\n",
      "Per-fold scores:\n",
      "\n",
      "RandomForest: [0.8899 0.8719 0.8364 0.858  0.8515]\n",
      "\n",
      "GradientBoosting: [0.8908 0.887  0.8652 0.8775 0.8701]\n",
      "\n",
      "GaussianNB: [0.8831 0.8663 0.837  0.8406 0.868 ]\n",
      "\n",
      "SVC_RBF: [0.8964 0.867  0.8559 0.8632 0.8598]\n",
      "\n",
      "LGBMClassifier: [0.8879 0.9006 0.8578 0.8751 0.8815]\n",
      "\n",
      "XGBClassifier: [0.8847 0.8947 0.842  0.8805 0.8865]\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "target = \"Survived\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SVC_RBF\": SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42),\n",
    "    \"LGBMClassifier\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=42, eval_metric=\"auc\")\n",
    "}\n",
    "\n",
    "results = evaluate_models_cv(X, y, models=models, n_splits=5, seed=42, return_oof=True)\n",
    "print_cv_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e0836",
   "metadata": {},
   "source": [
    "from these results we can see that LGBMClassifier made the best, but problem it had is quite bigger roc_auc_std and it had trained more time others. here the best result was seen by the GradientBoosting. but the problem is when i start using the optuna the models such as Xgboost or lgbm will give better result and they mostly perform faster and better result with bigger datasets. So my decision falls into Xgboost(much less time than lgbm and similar accuracy with the top 2 models). What needs to be done now is to check if the results are stable when the df is shuffled with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a594a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle-y sanity AUC (should be ~0.50): 0.46913498532095865\n"
     ]
    }
   ],
   "source": [
    "def sanity_check_shuffle_y(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    model,\n",
    "    seed: int = 42\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Shuffle target; AUC should drop to ~0.50. If not, suspect leakage/bug.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y_shuffled = pd.Series(rng.permutation(y.values), index=y.index)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    pipe = make_pipeline(model, X)\n",
    "\n",
    "    scores = cross_validate(pipe, X, y_shuffled, cv=cv, scoring=\"roc_auc\", n_jobs=-1)[\"test_score\"]\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# Optional leakage sanity check on your best model:\n",
    "leak_auc = sanity_check_shuffle_y(X, y, model=models[\"XGBClassifier\"], seed=42)\n",
    "print(\"Shuffle-y sanity AUC (should be ~0.50):\", leak_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a4d56",
   "metadata": {},
   "source": [
    "Why it should be 0.5? Actually it is quite simple with the basic prob. in this section of code, we change the target randomly therefore it no longer connected with the X_train. when it happens our value should be arounf 0.5 which means that it is 50 percent prob. to guess the target correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3328f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST ROC AUC: 0.813965744400527\n"
     ]
    }
   ],
   "source": [
    "# Final training + ONE test evaluation pattern:\n",
    "def train_final_and_eval_once(df: pd.DataFrame, target: str, best_model, seed: int = 42):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=seed\n",
    "    )\n",
    "\n",
    "    pipe = make_pipeline(best_model, X_train)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Get scores for AUC\n",
    "    try:\n",
    "        test_scores = pipe.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        test_scores = pipe.decision_function(X_test)\n",
    "\n",
    "    test_auc = roc_auc_score(y_test, test_scores)\n",
    "    return test_auc, pipe\n",
    "\n",
    "test_auc, final_pipe = train_final_and_eval_once(df, \"Survived\", best_model=models[\"XGBClassifier\"])\n",
    "print(\"FINAL TEST ROC AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee65677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "    num_cols = X.select_dtypes(include=[\"int64\", \"float64\", \"int32\", \"float32\"]).columns.tolist()\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=True))\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, num_cols),\n",
    "            (\"cat\", cat_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "\n",
    "def make_pipeline(model, X: pd.DataFrame) -> Pipeline:\n",
    "    return Pipeline(steps=[\n",
    "        (\"preprocess\", make_preprocessor(X)),\n",
    "        (\"model\", model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24609ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Optuna objective ----------\n",
    "def make_objective(X: pd.DataFrame, y: pd.Series, n_splits=5, seed=42):\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-2, 20.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 50.0, log=True),\n",
    "\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"tree_method\": \"hist\",   \n",
    "            \"random_state\": seed,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "\n",
    "        model = XGBClassifier(**params)\n",
    "\n",
    "        pipe = make_pipeline(model, X)\n",
    "\n",
    "        oof_scores = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\", n_jobs=-1)[:, 1]\n",
    "        auc = roc_auc_score(y, oof_scores)\n",
    "\n",
    "        return auc\n",
    "\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fede5bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-24 00:27:02,398] A new study created in memory with name: no-name-3a058527-a8ec-41aa-b3ed-4d37f42f460f\n",
      "[I 2026-01-24 00:27:02,631] Trial 0 finished with value: 0.8792248532685693 and parameters: {'n_estimators': 500, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'min_child_weight': 0.9466503798478175, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'gamma': 0.5808361216819946, 'reg_alpha': 0.6245760287469893, 'reg_lambda': 0.006763888939818983}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:02,795] Trial 1 finished with value: 0.8678485071208684 and parameters: {'n_estimators': 767, 'learning_rate': 0.010725209743171996, 'max_depth': 10, 'min_child_weight': 5.596520861285641, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503, 'gamma': 1.8340450985343382, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.0012291273711520685}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:02,886] Trial 2 finished with value: 0.8758747962803183 and parameters: {'n_estimators': 545, 'learning_rate': 0.02692655251486473, 'max_depth': 7, 'min_child_weight': 0.028871770589042903, 'subsample': 0.6460723242676091, 'colsample_bytree': 0.6831809216468459, 'gamma': 4.56069984217036, 'reg_alpha': 0.1165691561324743, 'reg_lambda': 8.642313649427712e-07}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:02,966] Trial 3 finished with value: 0.8524350493720639 and parameters: {'n_estimators': 611, 'learning_rate': 0.07500118950416987, 'max_depth': 2, 'min_child_weight': 1.0128002032729382, 'subsample': 0.5852620618436457, 'colsample_bytree': 0.5325257964926398, 'gamma': 9.488855372533333, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.6928219378948713}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,066] Trial 4 finished with value: 0.8785404616580919 and parameters: {'n_estimators': 443, 'learning_rate': 0.013940346079873234, 'max_depth': 8, 'min_child_weight': 0.28376353418686184, 'subsample': 0.5610191174223894, 'colsample_bytree': 0.7475884550556351, 'gamma': 0.34388521115218396, 'reg_alpha': 1.527156759251193, 'reg_lambda': 3.235186184144167e-06}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,167] Trial 5 finished with value: 0.8567437872154582 and parameters: {'n_estimators': 730, 'learning_rate': 0.028869220380495747, 'max_depth': 6, 'min_child_weight': 0.6378330678120924, 'subsample': 0.5924272277627636, 'colsample_bytree': 0.9847923138822793, 'gamma': 7.7513282336111455, 'reg_alpha': 2.854239907497756, 'reg_lambda': 4.774233225501719}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,259] Trial 6 finished with value: 0.8766763599953131 and parameters: {'n_estimators': 678, 'learning_rate': 0.22999586428143728, 'max_depth': 2, 'min_child_weight': 0.04435527819593249, 'subsample': 0.522613644455269, 'colsample_bytree': 0.6626651653816322, 'gamma': 3.8867728968948203, 'reg_alpha': 2.7678419414850017e-06, 'reg_lambda': 1.0911896618348114}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,338] Trial 7 finished with value: 0.8617528946835821 and parameters: {'n_estimators': 485, 'learning_rate': 0.026000059117302653, 'max_depth': 6, 'min_child_weight': 0.029187378749091768, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'gamma': 9.868869366005173, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 8.45935858243602e-07}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,389] Trial 8 finished with value: 0.8692439203655771 and parameters: {'n_estimators': 204, 'learning_rate': 0.1601531217136121, 'max_depth': 8, 'min_child_weight': 2.5496145492764652, 'subsample': 0.8856351733429728, 'colsample_bytree': 0.5370223258670452, 'gamma': 3.5846572854427263, 'reg_alpha': 1.1036250149900698e-07, 'reg_lambda': 2.3507921846521764}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,499] Trial 9 finished with value: 0.8625864144270815 and parameters: {'n_estimators': 699, 'learning_rate': 0.030816017044468066, 'max_depth': 2, 'min_child_weight': 0.1063070268375106, 'subsample': 0.6625916610133735, 'colsample_bytree': 0.864803089169032, 'gamma': 6.3755747135521315, 'reg_alpha': 0.9658611176861268, 'reg_lambda': 0.0003801879910537945}. Best is trial 0 with value: 0.8792248532685693.\n",
      "[I 2026-01-24 00:27:03,663] Trial 10 finished with value: 0.8861726264659828 and parameters: {'n_estimators': 957, 'learning_rate': 0.10251868762308501, 'max_depth': 10, 'min_child_weight': 11.954141254731399, 'subsample': 0.7606700059313507, 'colsample_bytree': 0.8451235367845726, 'gamma': 0.1514423710275688, 'reg_alpha': 0.004077450220493037, 'reg_lambda': 0.003417642467123239}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:03,821] Trial 11 finished with value: 0.8817973135632038 and parameters: {'n_estimators': 997, 'learning_rate': 0.10878192906783861, 'max_depth': 10, 'min_child_weight': 14.907613361750693, 'subsample': 0.7804533509078435, 'colsample_bytree': 0.8513496163789993, 'gamma': 0.11022393498478959, 'reg_alpha': 0.0014441715954419988, 'reg_lambda': 0.005479259091904685}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:03,947] Trial 12 finished with value: 0.8575267099138253 and parameters: {'n_estimators': 974, 'learning_rate': 0.08995147228189702, 'max_depth': 10, 'min_child_weight': 19.812580035542126, 'subsample': 0.7630125055985993, 'colsample_bytree': 0.8588729908849949, 'gamma': 2.1181069002489306, 'reg_alpha': 0.0007843098686773694, 'reg_lambda': 0.013257046018270303}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,075] Trial 13 finished with value: 0.8590286432535499 and parameters: {'n_estimators': 997, 'learning_rate': 0.09154387249271213, 'max_depth': 10, 'min_child_weight': 19.903313628359548, 'subsample': 0.7878475603784052, 'colsample_bytree': 0.8585787245031458, 'gamma': 1.873822903902111, 'reg_alpha': 0.002257242225205121, 'reg_lambda': 6.328572364105074e-05}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,206] Trial 14 finished with value: 0.8826707783423342 and parameters: {'n_estimators': 860, 'learning_rate': 0.13570390610987357, 'max_depth': 9, 'min_child_weight': 5.847920902231267, 'subsample': 0.9977408115016615, 'colsample_bytree': 0.9501945220447685, 'gamma': 0.37196786914287205, 'reg_alpha': 0.0070569457857090285, 'reg_lambda': 0.04878484950743042}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,336] Trial 15 finished with value: 0.8731558708550368 and parameters: {'n_estimators': 864, 'learning_rate': 0.05272751433892053, 'max_depth': 4, 'min_child_weight': 4.701698467788446, 'subsample': 0.9758970590679756, 'colsample_bytree': 0.9913430783889022, 'gamma': 3.015878050330267, 'reg_alpha': 0.019121543393403363, 'reg_lambda': 0.051549995552340855}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,472] Trial 16 finished with value: 0.8714169303039017 and parameters: {'n_estimators': 846, 'learning_rate': 0.1470783270444132, 'max_depth': 9, 'min_child_weight': 2.6082425111790624, 'subsample': 0.8607349956827237, 'colsample_bytree': 0.9298249375977756, 'gamma': 5.980329382857889, 'reg_alpha': 3.572194104139884e-05, 'reg_lambda': 1.342223397000441e-08}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,605] Trial 17 finished with value: 0.8574068748069325 and parameters: {'n_estimators': 880, 'learning_rate': 0.05307006740806038, 'max_depth': 9, 'min_child_weight': 7.786595691289573, 'subsample': 0.7172744518636274, 'colsample_bytree': 0.7847849004475568, 'gamma': 1.2961178326843026, 'reg_alpha': 0.005524129634058471, 'reg_lambda': 39.18960519792582}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,682] Trial 18 finished with value: 0.8838957594350174 and parameters: {'n_estimators': 357, 'learning_rate': 0.14982807062764933, 'max_depth': 5, 'min_child_weight': 0.26822931653917564, 'subsample': 0.9547281365288425, 'colsample_bytree': 0.9216961205137372, 'gamma': 2.4418092957561175, 'reg_alpha': 0.00014021547203370562, 'reg_lambda': 0.21369261204209855}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,769] Trial 19 finished with value: 0.885070143482568 and parameters: {'n_estimators': 365, 'learning_rate': 0.20273114187593994, 'max_depth': 4, 'min_child_weight': 0.2664253257485534, 'subsample': 0.8349352070629106, 'colsample_bytree': 0.7866804535238765, 'gamma': 2.415834261767888, 'reg_alpha': 7.645480501301263e-05, 'reg_lambda': 5.302782485793449e-05}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,850] Trial 20 finished with value: 0.8737417313776243 and parameters: {'n_estimators': 310, 'learning_rate': 0.2873789304832256, 'max_depth': 4, 'min_child_weight': 0.01130393702355208, 'subsample': 0.8314063332863684, 'colsample_bytree': 0.7598188547929215, 'gamma': 5.376990769240335, 'reg_alpha': 1.2722974438529106e-08, 'reg_lambda': 3.1587171421021876e-05}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:04,927] Trial 21 finished with value: 0.8839676604991532 and parameters: {'n_estimators': 380, 'learning_rate': 0.1625264397134928, 'max_depth': 4, 'min_child_weight': 0.222140897231168, 'subsample': 0.9458225774518073, 'colsample_bytree': 0.8140478300925844, 'gamma': 2.896276284752744, 'reg_alpha': 0.00013084466370348973, 'reg_lambda': 0.156580100379787}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:05,010] Trial 22 finished with value: 0.8794858275013582 and parameters: {'n_estimators': 368, 'learning_rate': 0.19491491541036526, 'max_depth': 4, 'min_child_weight': 0.11892331872855852, 'subsample': 0.707289201615861, 'colsample_bytree': 0.8033348792290621, 'gamma': 3.168352112576232, 'reg_alpha': 4.0105266159258014e-05, 'reg_lambda': 0.0003526203117288702}. Best is trial 10 with value: 0.8861726264659828.\n",
      "[I 2026-01-24 00:27:05,066] Trial 23 finished with value: 0.8876612447938304 and parameters: {'n_estimators': 223, 'learning_rate': 0.06837048929088113, 'max_depth': 3, 'min_child_weight': 0.14562866517985448, 'subsample': 0.9270432099755169, 'colsample_bytree': 0.7251262264535022, 'gamma': 1.3450286636868714, 'reg_alpha': 2.080369222752971e-06, 'reg_lambda': 4.0333588080212695e-05}. Best is trial 23 with value: 0.8876612447938304.\n",
      "[I 2026-01-24 00:27:05,132] Trial 24 finished with value: 0.8910246167939583 and parameters: {'n_estimators': 218, 'learning_rate': 0.06729541441294411, 'max_depth': 3, 'min_child_weight': 0.09814494707398377, 'subsample': 0.8232121114313015, 'colsample_bytree': 0.706126381006446, 'gamma': 1.2658083510165619, 'reg_alpha': 1.3123322346725386e-06, 'reg_lambda': 1.7155760107246582e-05}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,198] Trial 25 finished with value: 0.88351228709296 and parameters: {'n_estimators': 211, 'learning_rate': 0.04150530088383429, 'max_depth': 3, 'min_child_weight': 0.08372278948879941, 'subsample': 0.924846322558455, 'colsample_bytree': 0.671307955244884, 'gamma': 1.2934959925393643, 'reg_alpha': 3.7330168354077543e-07, 'reg_lambda': 4.1596431244680815e-06}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,267] Trial 26 finished with value: 0.8904360932689952 and parameters: {'n_estimators': 273, 'learning_rate': 0.06344158358463836, 'max_depth': 3, 'min_child_weight': 0.011008819083273785, 'subsample': 0.8141852769623694, 'colsample_bytree': 0.7088564294406411, 'gamma': 1.1674578668767732, 'reg_alpha': 4.751265518343537e-06, 'reg_lambda': 7.519230946325048e-08}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,334] Trial 27 finished with value: 0.8892270901905643 and parameters: {'n_estimators': 272, 'learning_rate': 0.06423506712447877, 'max_depth': 3, 'min_child_weight': 0.010661376922551752, 'subsample': 0.8280785058259055, 'colsample_bytree': 0.7142359417750929, 'gamma': 1.10395141994251, 'reg_alpha': 4.060245825522732e-06, 'reg_lambda': 1.2714551947415339e-08}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,412] Trial 28 finished with value: 0.8745779141234994 and parameters: {'n_estimators': 285, 'learning_rate': 0.037319496306454106, 'max_depth': 3, 'min_child_weight': 0.010629083834757814, 'subsample': 0.8157917401480089, 'colsample_bytree': 0.6323585999023397, 'gamma': 4.431029228151999, 'reg_alpha': 3.992759394191284e-07, 'reg_lambda': 1.8369255460358402e-08}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,489] Trial 29 finished with value: 0.888273735340172 and parameters: {'n_estimators': 293, 'learning_rate': 0.06781238782199553, 'max_depth': 5, 'min_child_weight': 0.020638815392010647, 'subsample': 0.7085820980112907, 'colsample_bytree': 0.7032314275733221, 'gamma': 0.9375854847806887, 'reg_alpha': 7.843761723006932e-06, 'reg_lambda': 1.0140330461624882e-07}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,577] Trial 30 finished with value: 0.8661148925744842 and parameters: {'n_estimators': 419, 'learning_rate': 0.04347302644251415, 'max_depth': 3, 'min_child_weight': 0.06004136587672082, 'subsample': 0.8548862971582968, 'colsample_bytree': 0.6145002745049484, 'gamma': 7.287733564458421, 'reg_alpha': 2.585215101506681e-08, 'reg_lambda': 7.222621550671188e-08}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,664] Trial 31 finished with value: 0.8879621640622504 and parameters: {'n_estimators': 280, 'learning_rate': 0.06734888647615142, 'max_depth': 5, 'min_child_weight': 0.01760736558501237, 'subsample': 0.7060941172557418, 'colsample_bytree': 0.718102756781861, 'gamma': 0.9920402940476131, 'reg_alpha': 1.0316167143678261e-05, 'reg_lambda': 1.062610819871003e-07}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,744] Trial 32 finished with value: 0.8906917414970335 and parameters: {'n_estimators': 251, 'learning_rate': 0.05610480654763627, 'max_depth': 5, 'min_child_weight': 0.019971177038467017, 'subsample': 0.8002909474624987, 'colsample_bytree': 0.6995043907153701, 'gamma': 0.7767191133385749, 'reg_alpha': 6.224294278745668e-07, 'reg_lambda': 1.304887271109902e-07}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,823] Trial 33 finished with value: 0.8819970387413585 and parameters: {'n_estimators': 264, 'learning_rate': 0.018753260199202402, 'max_depth': 3, 'min_child_weight': 0.038688575591911266, 'subsample': 0.8035030765963237, 'colsample_bytree': 0.6467888599907716, 'gamma': 1.6481109258598998, 'reg_alpha': 6.145326970254058e-07, 'reg_lambda': 4.7501376761036307e-07}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,900] Trial 34 finished with value: 0.8834909830739569 and parameters: {'n_estimators': 327, 'learning_rate': 0.05421174805350227, 'max_depth': 2, 'min_child_weight': 0.016844209133583893, 'subsample': 0.7374821279913888, 'colsample_bytree': 0.5916490401535851, 'gamma': 0.8456738670172873, 'reg_alpha': 1.1704842776082182e-07, 'reg_lambda': 7.203925424812789e-06}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:05,987] Trial 35 finished with value: 0.8873017394731516 and parameters: {'n_estimators': 563, 'learning_rate': 0.07881691665049449, 'max_depth': 7, 'min_child_weight': 0.010644249681159719, 'subsample': 0.8624972197823969, 'colsample_bytree': 0.6868805900511863, 'gamma': 2.0740261583536683, 'reg_alpha': 1.5772652088068316e-06, 'reg_lambda': 2.6274931706754575e-07}. Best is trial 24 with value: 0.8910246167939583.\n",
      "[I 2026-01-24 00:27:06,064] Trial 36 finished with value: 0.8920365576966095 and parameters: {'n_estimators': 243, 'learning_rate': 0.03666482838050812, 'max_depth': 5, 'min_child_weight': 0.02562133314695501, 'subsample': 0.6593062469411188, 'colsample_bytree': 0.7473769928469448, 'gamma': 0.8656742942809635, 'reg_alpha': 1.630330926122681e-05, 'reg_lambda': 3.8117031449276377e-08}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,162] Trial 37 finished with value: 0.8893549143045836 and parameters: {'n_estimators': 242, 'learning_rate': 0.021309407791762703, 'max_depth': 5, 'min_child_weight': 0.02621078190443316, 'subsample': 0.6523790762424088, 'colsample_bytree': 0.7424854810677135, 'gamma': 0.0187282119418537, 'reg_alpha': 1.8493467449504076e-05, 'reg_lambda': 1.3523940023994849e-06}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,261] Trial 38 finished with value: 0.8810410208885906 and parameters: {'n_estimators': 421, 'learning_rate': 0.03365475875033986, 'max_depth': 6, 'min_child_weight': 0.052311543431953544, 'subsample': 0.6288573267572102, 'colsample_bytree': 0.7629456161441163, 'gamma': 2.5840697235487973, 'reg_alpha': 7.349557945438706e-08, 'reg_lambda': 3.427586569387072e-08}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,360] Trial 39 finished with value: 0.886074095378093 and parameters: {'n_estimators': 489, 'learning_rate': 0.04582674729337026, 'max_depth': 7, 'min_child_weight': 0.07278636434770154, 'subsample': 0.6800853294548285, 'colsample_bytree': 0.6868441896182621, 'gamma': 0.6713896248433112, 'reg_alpha': 0.0002550909687118317, 'reg_lambda': 1.3399783226939117e-05}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,416] Trial 40 finished with value: 0.8728576145889922 and parameters: {'n_estimators': 201, 'learning_rate': 0.023923209511375026, 'max_depth': 6, 'min_child_weight': 0.03450739271689486, 'subsample': 0.5590573002007949, 'colsample_bytree': 0.5778610056515864, 'gamma': 3.8350762904314766, 'reg_alpha': 9.775568909253978e-07, 'reg_lambda': 1.7739042839378531e-06}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,492] Trial 41 finished with value: 0.8905559283758882 and parameters: {'n_estimators': 244, 'learning_rate': 0.020939153876059557, 'max_depth': 5, 'min_child_weight': 0.023572018777612894, 'subsample': 0.6501078796649276, 'colsample_bytree': 0.7389766599905837, 'gamma': 0.5142768668109181, 'reg_alpha': 1.6489099200999043e-05, 'reg_lambda': 3.4601611784050483e-07}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,570] Trial 42 finished with value: 0.8851899785894608 and parameters: {'n_estimators': 326, 'learning_rate': 0.01553878937228125, 'max_depth': 5, 'min_child_weight': 0.021094190493745456, 'subsample': 0.7458385844062413, 'colsample_bytree': 0.7414350796137921, 'gamma': 1.6185198501949118, 'reg_alpha': 1.4794456571944317e-05, 'reg_lambda': 3.2590459371823334e-07}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,659] Trial 43 finished with value: 0.8900419689174364 and parameters: {'n_estimators': 234, 'learning_rate': 0.03507645979363265, 'max_depth': 5, 'min_child_weight': 0.0439725197723297, 'subsample': 0.6088435881640019, 'colsample_bytree': 0.6585837944378643, 'gamma': 0.5920111583543299, 'reg_alpha': 5.727275941016519e-06, 'reg_lambda': 5.5434276770494693e-08}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,779] Trial 44 finished with value: 0.8644318750732326 and parameters: {'n_estimators': 639, 'learning_rate': 0.010661223528944622, 'max_depth': 6, 'min_child_weight': 0.015399174352422553, 'subsample': 0.7781167939941622, 'colsample_bytree': 0.6984855257479871, 'gamma': 8.602388794499966, 'reg_alpha': 1.3366244720523807e-07, 'reg_lambda': 3.755644312672483e-07}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,835] Trial 45 finished with value: 0.8746045441472533 and parameters: {'n_estimators': 249, 'learning_rate': 0.01588783759590154, 'max_depth': 2, 'min_child_weight': 0.953498627771116, 'subsample': 0.5033408236857996, 'colsample_bytree': 0.7339643289218374, 'gamma': 0.5536968608015636, 'reg_alpha': 0.00047105485542390423, 'reg_lambda': 1.7903245308600067e-07}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:06,912] Trial 46 finished with value: 0.8835868511594713 and parameters: {'n_estimators': 330, 'learning_rate': 0.029782803968801654, 'max_depth': 4, 'min_child_weight': 0.0274936243529147, 'subsample': 0.6783902585384227, 'colsample_bytree': 0.7669900216925999, 'gamma': 1.8579504941197718, 'reg_alpha': 2.7107158490415825e-06, 'reg_lambda': 9.340937483724259e-07}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:07,061] Trial 47 finished with value: 0.887711841838963 and parameters: {'n_estimators': 458, 'learning_rate': 0.01322938834914508, 'max_depth': 7, 'min_child_weight': 0.014494835825934273, 'subsample': 0.6249999530722324, 'colsample_bytree': 0.8306141276725814, 'gamma': 0.41059234899924446, 'reg_alpha': 3.252884889644586e-07, 'reg_lambda': 3.679907399866969e-08}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:07,129] Trial 48 finished with value: 0.8906065254210207 and parameters: {'n_estimators': 395, 'learning_rate': 0.1139134905843508, 'max_depth': 5, 'min_child_weight': 0.6626462897543338, 'subsample': 0.5578647547680121, 'colsample_bytree': 0.6322180170958611, 'gamma': 1.5919469341013424, 'reg_alpha': 3.1067307450384324e-05, 'reg_lambda': 2.2756090190348152e-06}. Best is trial 36 with value: 0.8920365576966095.\n",
      "[I 2026-01-24 00:27:07,279] Trial 49 finished with value: 0.85872772398513 and parameters: {'n_estimators': 535, 'learning_rate': 0.11847855523266479, 'max_depth': 6, 'min_child_weight': 0.6081857630664772, 'subsample': 0.5200537887988089, 'colsample_bytree': 0.6173685878452784, 'gamma': 0.009925481813169323, 'reg_alpha': 3.124289263402939e-05, 'reg_lambda': 3.2477540836695038e-06}. Best is trial 36 with value: 0.8920365576966095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.8920365576966095\n",
      "Best params: {'n_estimators': 243, 'learning_rate': 0.03666482838050812, 'max_depth': 5, 'min_child_weight': 0.02562133314695501, 'subsample': 0.6593062469411188, 'colsample_bytree': 0.7473769928469448, 'gamma': 0.8656742942809635, 'reg_alpha': 1.630330926122681e-05, 'reg_lambda': 3.8117031449276377e-08}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Run Optuna ----------\n",
    "def tune_xgb_optuna(X, y, n_trials=50, seed=42):\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(make_objective(X, y, n_splits=5, seed=seed), n_trials=n_trials)\n",
    "\n",
    "    print(\"Best AUC:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_params)\n",
    "    return study\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "study = tune_xgb_optuna(X, y, n_trials=50, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e15c8",
   "metadata": {},
   "source": [
    "without tuning the auc was about 0.87, it increases by 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6a1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST AUC: 0.8432147562582346\n"
     ]
    }
   ],
   "source": [
    "# ---------- Train final model and evaluate on test ----------\n",
    "def train_final_once(df: pd.DataFrame, target: str, best_params: dict, seed: int = 42):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=seed\n",
    "    )\n",
    "\n",
    "    final_params = dict(best_params)\n",
    "    final_params.update({\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"random_state\": seed,\n",
    "        \"n_jobs\": -1\n",
    "    })\n",
    "\n",
    "    model = XGBClassifier(**final_params)\n",
    "    pipe = make_pipeline(model, X_train)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    test_scores = pipe.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, test_scores)\n",
    "\n",
    "    print(\"FINAL TEST AUC:\", test_auc)\n",
    "    return pipe, test_auc\n",
    "\n",
    "final_pipe, test_auc = train_final_once(df, target, study.best_params, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4542b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF ROC AUC: 0.8920365576966095\n",
      "OOF PR AUC (Average Precision): 0.8667218157217855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, confusion_matrix,\n",
    "    precision_score, recall_score, f1_score, classification_report\n",
    ")\n",
    "seed = 42\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "best_model = XGBClassifier(\n",
    "    **study.best_params,\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=seed,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(best_model, X)  # uses your make_pipeline + preprocessing\n",
    "\n",
    "oof_proba = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\", n_jobs=-1)[:, 1]\n",
    "\n",
    "print(\"OOF ROC AUC:\", roc_auc_score(y, oof_proba))\n",
    "print(\"OOF PR AUC (Average Precision):\", average_precision_score(y, oof_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a68bd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (max F1): 0.3768992\n",
      "Precision: 0.7915492957746478 Recall: 0.8216374269005848 F1: 0.8063127690095432\n"
     ]
    }
   ],
   "source": [
    "prec, rec, thresh = precision_recall_curve(y, oof_proba)\n",
    "\n",
    "f1 = 2 * (prec[1:] * rec[1:]) / (prec[1:] + rec[1:] + 1e-12)\n",
    "\n",
    "best_idx = np.argmax(f1)\n",
    "best_threshold_f1 = thresh[best_idx]\n",
    "\n",
    "print(\"Best threshold (max F1):\", best_threshold_f1)\n",
    "print(\"Precision:\", prec[best_idx + 1], \"Recall:\", rec[best_idx + 1], \"F1:\", f1[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a046bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[474  75]\n",
      " [ 61 281]]\n",
      "Precision: 0.7893258426966292\n",
      "Recall: 0.8216374269005848\n",
      "F1: 0.8051575931232091\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       549\n",
      "           1       0.79      0.82      0.81       342\n",
      "\n",
      "    accuracy                           0.85       891\n",
      "   macro avg       0.84      0.84      0.84       891\n",
      "weighted avg       0.85      0.85      0.85       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = best_threshold_f1  \n",
    "\n",
    "pred = (oof_proba >= threshold).astype(int)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y, pred))\n",
    "print(\"Precision:\", precision_score(y, pred))\n",
    "print(\"Recall:\", recall_score(y, pred))\n",
    "print(\"F1:\", f1_score(y, pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d947db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(Path(os.getcwd()).parent / \"artifacts\" / \"model_data\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672861bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, json\n",
    "MODEL_PATH = Path(os.getcwd()).parent / \"artifacts\" / \"model_data\" / \"xgb_pipeline.joblib\"\n",
    "joblib.dump(final_pipe, MODEL_PATH)\n",
    "DATA_PATH=Path(os.getcwd()).parent / \"artifacts\" / \"model_data\" / \"threshold.json\"\n",
    "with open(DATA_PATH, \"w\") as f:\n",
    "    json.dump({\"threshold_f1\": float(threshold)}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0b18d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=study.best_params\n",
    "out = Path(os.getcwd()).parent / \"artifacts\" / \"model_data\" / \"best_params.json\"\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_params, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "160638fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"best_value\": float(study.best_value),\n",
    "    \"best_params\": study.best_params\n",
    "} \n",
    "out = Path(os.getcwd()).parent / \"artifacts\" / \"model_data\" / \"best_score.json\"\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
